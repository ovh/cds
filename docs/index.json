[
{
	"uri": "/getting-started/about-cds/",
	"title": "About CDS",
	"tags": [],
	"description": "",
	"content": "What is CDS? CDS is a Continuous Delivery solution with an architecture featuring: A complete isolation between tenants High availability oriented architecture Automatic scaling Automation oriented with iso-feature API, CLI and WebUI Designed for scalability, CDS tasks can run either on cloud infrastructure or on your own machines, should you start some workers using a hatchery. CDS exposes an API available to workers and humans through cli or WebUI. What does CDS do? Basically, CDS allows users to create building and delivery pipelines for all your applications. An application is composed of one or multiple pipelines, that can be triggered: manually by VCS change by another pipeline by a hook General Creation of build and deployment pipelines Simple organisation by projects and applications Artifact storage available trough UI, API and CLI Reusable build and deployment Actions Packaging Declaration of worker models (specific hosts, docker image, openstack recipe) Conditional build path depending of build parameters (ie: git branch) Deployment Completely cross platform workers (built in Go) without any dependency Support for deployment environments (different sets of variable for the same deployment pipeline) Basic principles A action will start on any worker matching all its requirements Every action runs in a different worker, all build data needed for the next step should be uploaded as artifact It is possible to run some of your pipelines on-premise, some on CDS workers "
},
{
	"uri": "/building-pipelines/actions/builtin/",
	"title": "Built-in Actions",
	"tags": [],
	"description": "",
	"content": "User actions use built-in action(s) and / or other existing action(s). There can be created by CLI and / or Web UI. User actions from CDS Contributions : Artifact Download Artifact Upload GitClone JUnit Script "
},
{
	"uri": "/getting-started/",
	"title": "Getting started",
	"tags": [],
	"description": "",
	"content": "Discover what is CDS and the core-concepts behind it. About CDS Concepts Installation "
},
{
	"uri": "/advanced/repositories_manager/github/",
	"title": "Github",
	"tags": [],
	"description": "",
	"content": "Authorize CDS on Github Create a CDS application on Github Go to https://github.com/settings/developers and Register a new application: set an application name, the url and a description. Dont set up Authorization callback URL. On the next page Github give you a Client ID and a Client Secret Connect CDS To Github With CDS CLI run : $ cds admin reposmanager add GITHUB github http://github.com client-id=&amp;lt;your_client_id&amp;gt; client-secret=&amp;lt;client-secret&amp;gt; If you use Vault as Secret Manager: Set in Vault you CDS Client Secret in a secret named : cds/repositoriesmanager-secrets-github.com.net-client-secret If you&amp;rsquo;re not using vault: Set env CDS_VCS_REPOSITORIES_GITHUB_CLIENTSECRET or update your configuration file with &amp;lt;client-secret&amp;gt;: [vcs.repositories.github] clientsecret = &amp;quot;&amp;lt;client-secret&amp;gt;&amp;quot; Then restart CDS. Now check everything is OK with : $ cds admin reposmanager list "
},
{
	"uri": "/advanced/hatcheries/",
	"title": "Hatcheries",
	"tags": [],
	"description": "",
	"content": "Hatchery is a binary dedicated to spawn and kill worker in accordance with build queue needs. An hatchery is started with permissions to build all pipelines accessible from a given group, using token generated by user. There are 5 modes for hatcheries: Local (Start workers on a single host) Local Docker (Start worker model instances on a single host) Marathon (Start worker model instances on a mesos cluster with marathon framework) Swarm (Start worker on a docker swarm cluster) Openstack (Start hosts on an openstack cluster) Local mode Hatchery starts workers directly as local process. Docker mode Hatchery starts workers inside docker containers on the same host. Marathon mode Hatchery starts workers inside containers on a mesos cluster using Marathon API. Openstack mode Hatchery starts workers on Openstack servers using Openstack Nova. Swarm mode The hatchery connects to a swarm cluster and starts workers inside containers. Admin hatchery As a CDS administrator, it is possible to generate an access token for all projects using the shared.infra group. This group is builtin to CDS, and has the following properties: All CDS administrators are administrator of this group At pipeline creation, this group is added with Read/Execution permission automatically This means that by default, an hatchery using a token generated for this group will be able to build all pipelines. Should a user want to avoid building on shared infrastructure, he only need to remove access of shared.infra group to his pipeline. "
},
{
	"uri": "/getting-started/concepts/pipeline/",
	"title": "Pipeline",
	"tags": [],
	"description": "",
	"content": "A pipeline describes how things need to be executed in order to achieve wanted result. In CDS, a pipeline a defined on a project and can be used on several applications inside the same project. A pipeline is structured in sequential stages containing one or multiple concurrent jobs. In CDS there is several types of pipeline : build, testing and deployment. In Pipeline configuration file, default type is build. The goal is to make your pipeline the more reusable as possible. It have to be able to build, test or deploy all the tiers, services or micro-services of your project. You can also define ACL on a pipeline. Triggers Example "
},
{
	"uri": "/getting-started/installation/requirements/",
	"title": "Requirements",
	"tags": [],
	"description": "",
	"content": "CDS API is the core component of CDS. To start CDS api, the only mandatory dependency is a PostgreSQL database and a path to the directory containing other CDS binaries. There is are two ways to set up CDS: as toml configuration over environment variables. CDS API Third-parties At the minimum, CDS needs a PostgreSQL Database &amp;gt;= 9.4. But for serious usage your may need : A Redis server or sentinels based cluster used as a cache and session store A LDAP Server for authentication A SMTP Server for mails A Kafka Broker to manage CDS events A Openstack Swift Tenant to store builds artifacts A Vault server for cipher and app keys A Consul to manage CDS Configuration See Configuration template for more details Supported Platforms FreeBSD i386/amd64/arm Linux i386/amd64/arm(raspberry pi) Windows/amd64 Darwin i386/amd64 OpenBDS amd64 Solaris amd64 You&amp;rsquo;ll find binaries for Linux amd64/arm, Windows amd64, Darwin amd64 and FreeBSD amd64 on CDS Releases "
},
{
	"uri": "/building-pipelines/actions/user-actions/",
	"title": "User Actions",
	"tags": [],
	"description": "",
	"content": "CDS User Actions are developed in CDS. There are available on all CDS Installation. Built-in actions : cds-docker-package cds-nexus-upload cds-perl-test "
},
{
	"uri": "/tutorials/worker-setup/",
	"title": "Worker Setup",
	"tags": [],
	"description": "",
	"content": "Introduction Why would you need to setup your own worker ? There is several cases where one would need to setup his own worker: Perform incremental build Build on a specific architecture Perform integration tests in a specific network How does this work ? Workers authenticate on CDS with a token and have the same permissions as the user who generated it. Bottom line, if you can access the application, your worker will too. Linux Setup Download the binary Simple enough, run $ wget -nv https://your-cds-api/download/worker/`uname -m` -O worker or download from https://github.com/ovh/cds/releases Startup the worker $ worker --help CDS Worker Usage: worker [flags] worker [command] Available Commands: export worker export &amp;lt;varname&amp;gt; &amp;lt;value&amp;gt; upload worker upload --tag=&amp;lt;tag&amp;gt; &amp;lt;path&amp;gt; version Print the version number register worker register Flags: --api string URL of CDS API --basedir string Worker working directory --booked-job-id int Booked job id --graylog-extra-key string Ex: --graylog-extra-key=xxxx-yyyy --graylog-extra-value string Ex: --graylog-extra-value=xxxx-yyyy --graylog-host string Ex: --graylog-host=xxxx-yyyy --graylog-port string Ex: --graylog-port=12202 --graylog-protocol string Ex: --graylog-protocol=xxxx-yyyy --grpc-api string CDS GRPC tcp address --grpc-insecure Disable GRPC TLS encryption --hatchery int Hatchery spawing worker --key string CDS KEY --log-level string Log Level : debug, info, notice, warning, critical (default &amp;quot;notice&amp;quot;) --model int Model of worker --name string Name of worker --single-use Exit after executing an action --ttl int Worker time to live (minutes) (default 30) Use &amp;quot;worker [command] --help&amp;quot; for more information about a command. Mandatory parameters are &amp;ndash;api and &amp;ndash;key. The most basic way to start a worker is as following: $ worker --api=https://your-cds-api --key=NTU2ZmFiOGZmMzI5MGU1NzVmY2FhNThmOTY3NjFmMDVmNmIxOTFhNDViNjRjETCETC 2016/03/24 11:30:50 [NOTICE] What a good time to be alive 2016/03/24 11:30:50 [NOTICE] Disconnected from CDS engine, trying to register... 2016/03/24 11:30:50 [NOTICE] Registering [desk32345] at [https://your-cds-api] That&amp;rsquo;s it, you are done here. Windows Setup Download the binary Download the windows binary from https://github.com/ovh/cds/releases Prerequisites CDS Worker will launch Microsoft Powershell command. Please check Powershell is correctly installed and configured on your host. Every command CDS Worker will launch should be in the %PATH% variable. Do the following steps with the target User whom will run the CDS Worker. To be able to operate git clone commands, you have to follow next steps : Install Git https://git-scm.com/download/win Setup your system %PATH%, and add C:\Program Files\Git\mingw32\bin;C:\Program Files\Git\usr\bin In a Powershell Prompt, generate SSH keys to be able PS ssh-keygen In a Powsershell Prompt, run PS Set-ExecutionPolicy Unrestricted Add the public key as Access Key in every project in stash you will have to clone : * Stash &amp;gt; Project &amp;gt; Settings &amp;gt; Access Keys &amp;gt; Add Key * . Copy the id_rsa and id_rsa.pub from you C:\Users\&amp;lt;user&amp;gt;\.ssh\ directory to C:\Program Files\Git\etc\ssh\ (Optional, just for example here) Edit or Create the file C:\Program Files\Git\etc\ssh\ssh_config : Host your-bitbucket-host StrictHostKeyChecking no You may want to improve your Git Experience on your windows host : have a look to posh-git : https://git-scm.com/book/en/v2/Git-in-Other-Environments-Git-in-Powershell Trigger your pipeline on your Host If you want to force you pipeline execution on your host, add a &amp;ldquo;hostname&amp;rdquo; requirement on you pipeline and set it to the hostname of your windows host. "
},
{
	"uri": "/advanced/repositories_manager/bitbucket/",
	"title": "Bitbucket",
	"tags": [],
	"description": "",
	"content": "Authorize CDS on your Bitbucket instance You need to perform the following steps : Bitbucket admin privileges A RSA Key Pair Create a CDS application in BitBucket In Bitbucket go to Administration Settings / Application Links. Create a new Application with : Name : CDS Type : Generic Application Application URL : Your CDS URL Display URL : Your CDS URL On this application, you just have to set up OAuth Incoming Authentication : Consumer Key : CDS Consumer Name : CDS Public Key : Your CDS RSA public key Consumer Callback URL : None Allow 2-Legged OAuth : false Execute as : None Allow user impersonation through 2-Legged OAuth : false Connect CDS To Bitbucket With CDS CLI run : $ cds admin reposmanager add STASH mystash.mynetwork.net http://mystash.mynetwork.net key=privatekey And follow instructions. Set in Vault you CDS private key in a secret named : cds/repositoriesmanager-secrets-mystash.mynetwork.net-privatekey Restart CDS. Now check everything is OK with : $ cds admin reposmanager list "
},
{
	"uri": "/building-pipelines/",
	"title": "Building Pipelines",
	"tags": [],
	"description": "",
	"content": "Actions Templates Variables Requirements "
},
{
	"uri": "/getting-started/concepts/",
	"title": "Concepts",
	"tags": [],
	"description": "",
	"content": "Project A project contains applications, pipelines and environments. A project is the first level of permissions management. Any CDS application has to be created inside a project. The project key has to be unique amongst all projects in CDS. At creation, a project has to have at least one group with edition permissions on it. It is possible to use either an existing group or create a new one. If the provided group does not exists, the group will be created with edition permissions on project and creating user will automatically join the group. Application An application represents a real world production unit. An application lives inside a project, has variables and can attach: Pipelines Environments Environment An environment is created inside a project and can be used by all applications inside given project. "
},
{
	"uri": "/getting-started/installation/download/",
	"title": "Download",
	"tags": [],
	"description": "",
	"content": "You&amp;rsquo;ll find last release of CDS on Github Releases "
},
{
	"uri": "/advanced/hatcheries/openstack/",
	"title": "Hatchery Openstack",
	"tags": [],
	"description": "",
	"content": "CDS build using OVH.com Openstack infrastructure Start Opentack hatchery Generate a token for group: $ cds generate token -g shared.infra -e persistent fc300aad48242d19e782a37d361dfa3e55868a629e52d7f6825c7ce65a72bf92 Then start hatchery: OPENSTACK_USER=&amp;lt;user&amp;gt; OPENSTACK_TENANT=&amp;lt;tenant&amp;gt; OPENSTACK_AUTH_ENDPOINT=https://auth.cloud.ovh.net OPENSTACK_PASSWORD=&amp;lt;password&amp;gt; OPENSTACK_REGION=SBG1 hatchery openstack \ --api=https://api.domain \ --max-worker=10 \ --provision=1 \ --token=fc300aad48242d19e782a37d361dfa3e55868a629e52d7f6825c7ce65a72bf92 This hatchery will now start worker of model &amp;lsquo;docker&amp;rsquo; on OVH.com Openstack infrastructure when a pipeline is in queue with requirement docker. Setup a worker model See Tutorial "
},
{
	"uri": "/building-pipelines/actions/plugins/",
	"title": "Plugins Actions",
	"tags": [],
	"description": "",
	"content": "CDS Plugin System lets users develop complex actions. See How to write a plugin CDS Administrators have to import plugins on CDS to let user use them. Plugins from CDS Contributions: plugin-download plugin-group-tmpl plugin-kafka-publish plugin-marathon plugin-ssh-cmd plugin-tmpl plugin-venom "
},
{
	"uri": "/advanced/repositories_manager/",
	"title": "Repositories Manager",
	"tags": [],
	"description": "",
	"content": "CDS can be linked to following repositories manager : Atlassian Stash Github It allows you to enable some CDS features such as : Create application in CDS from Stash or Github Attach an application to its Stash or Github repository Fully automatic hook management Branch filtering on application workflows Commit logs on pipeline build details Go through this tutorial to enable the link between repositories managers and CDS. You need CDS admin privileges to perform the following steps. Download and install properly the CDS CLI. "
},
{
	"uri": "/tutorials/worker-model-docker-simple/",
	"title": "Setup Worker Model Docker Simple",
	"tags": [],
	"description": "",
	"content": "A worker model of type docker can be spawned by a Hatchery Docker or Docker Swarm Register a worker Model from a existing Docker Image Docker Image golang:1.8.1 have a &amp;ldquo;curl&amp;rdquo; in $PATH, so it can be used as it is. In the UI, click on the wheel on the hand right top corner and select *workers&amp;rdquo; (or go the the route #/worker) At the bottom of the page, fill the form Name of your worker Golang-1.8.1 type docker image golang:1.8.1 Click on Add button and that&amp;rsquo;s it "
},
{
	"uri": "/advanced/worker/model/",
	"title": "Worker Model",
	"tags": [],
	"description": "",
	"content": "Purpose The goal of CDS is to start a worker when you need it and matching all your requirements exactly. In order to scale automatically on demand, it is possible to register a worker model. The goal of worker model is to describe the capabities of a given docker/iso image in terms of architecture, pre-installed binaries or libraries. Types There is 2 types of worker models: Docker images, see how to create a worker model docker Openstack images, see how to create a worker model openstack Capabilities Capabilities have a name, a type and a value. Existing capabilities type are: Binary Network access Hostname Memory Service Behavior All registered CDS hatcheries get the number of instances of each model needed. They then start/kill worker accordingly. "
},
{
	"uri": "/getting-started/installation/configuration/",
	"title": "Configuration",
	"tags": [],
	"description": "",
	"content": "The toml configuration can be provided by a file or via consul k/v store. Start CDS with local configuration file You can also generate a configuration file template with the following command. $ $PATH_TO_CDS/api --config my_conf_file.toml Generating default config file my_conf_file.toml Edit this file. Run CDS $ $PATH_TO_CDS/api --config my_conf_file.toml Reading configuration file my_new_file.toml 2017/04/04 16:33:17 [NOTICE] Starting CDS server... ... Start CDS with Consul Upload your toml configuration to consul $ consul kv put cds/config.api.toml - &amp;lt;PASTE YOUR CONFIGURATION&amp;gt; &amp;lt;ENDS WITH CRTL-D&amp;gt; Success! Data written to: cds/config.api.toml Run CDS $ $PATH_TO_CDS/api --remote-config localhost:8500 --remote-config-key cds/config.api.toml Reading configuration from localhost:8500 2017/04/04 16:11:25 [NOTICE] Starting CDS server... ... TOML Configuration template ################################### # CDS Configuration file template # ################################### # Please update this file with your own settings # # Note that you can override the configuration file with environments variables # CDS_URL_API # CDS_URL_UI # CDS_SERVER_HTTP_PORT # CDS_SERVER_HTTP_SESSIONTTL # CDS_SERVER_GRPC_PORT # CDS_SERVER_SECRETS_KEY # CDS_SERVER_SECRETS_BACKEND # CDS_SERVER_SECRETS_BACKEND_OPTION # CDS_LOG_LEVEL # CDS_DB_USER # CDS_DB_PASSWORD # CDS_DB_NAME # CDS_DB_HOST # CDS_DB_PORT # CDS_DB_SSLMODE # CDS_DB_MAXCONN # CDS_DB_TIMEOUT # CDS_DB_SECRET # CDS_CACHE_MODE # CDS_CACHE_TTL # CDS_CACHE_REDIS_HOST # CDS_CACHE_REDIS_PASSWORD # CDS_DIRECTORIES_DOWNLOAD # CDS_DIRECTORIES_KEYS # CDS_AUTH_LOCALMODE # CDS_AUTH_LDAP_ENABLE # CDS_AUTH_LDAP_HOST # CDS_AUTH_LDAP_PORT # CDS_AUTH_LDAP_SSL # CDS_AUTH_LDAP_BASE # CDS_AUTH_LDAP_DN # CDS_AUTH_LDAP_FULLNAME # CDS_AUTH_DEFAULTGROUP # CDS_AUTH_SHAREDINFRA_TOKEN # CDS_SMTP_DISABLE # CDS_SMTP_HOST # CDS_SMTP_PORT # CDS_SMTP_TLS # CDS_SMTP_USER # CDS_SMTP_PASSWORD # CDS_SMTP_FROM # CDS_ARTIFACT_MODE # CDS_ARTIFACT_LOCAL_BASEDIR # CDS_ARTIFACT_OPENSTACK_URL # CDS_ARTIFACT_OPENSTACK_USERNAME # CDS_ARTIFACT_OPENSTACK_PASSWORD # CDS_ARTIFACT_OPENSTACK_TENANT # CDS_ARTIFACT_OPENSTACK_REGION # CDS_ARTIFACT_OPENSTACK_CONTAINERPREFIX # CDS_EVENTS_KAFKA_ENABLED # CDS_EVENTS_KAFKA_BROKER # CDS_EVENTS_KAFKA_TOPIC # CDS_EVENTS_KAFKA_USER # CDS_EVENTS_KAFKA_PASSWORD # CDS_SCHEDULERS_DISABLED # CDS_VCS_POLLING_DISABLED # CDS_VCS_REPOSITORIES_GITHUB_STATUSES_DISABLED # CDS_VCS_REPOSITORIES_GITHUB_STATUSES_URL_DISABLED # CDS_VCS_REPOSITORIES_GITHUB_CLIENTSECRET # CDS_VCS_REPOSITORIES_BITBUCKET_STATUSES_DISABLED # CDS_VCS_REPOSITORIES_BITBUCKET_PRIVATEKEY ##################### # CDS URLs Settings # ##################### # Set the URLs from the user&#39;s point of view. It may be URL of your reverse proxy if you use one. [url] api = &amp;quot;http://localhost:8081&amp;quot; ui = &amp;quot;http://localhost:8080&amp;quot; ##################### # CDS Logs Settings # ##################### # Define log levels and hooks [log] # debug, info, warning or error level = &amp;quot;info&amp;quot; # CDS needs local directories to store temporary data (keys) and serve cds binaries such as hatcheries and workers (download) [directories] download = &amp;quot;/app&amp;quot; keys = &amp;quot;/app/keys&amp;quot; ########################### # General server settings # ########################### [server] [server.http] port = 8081 sessionTTL = 60 [server.grpc] port = 8082 [server.secrets] # AES Cypher key for database encryption. 32 char. # This is mandatory key = &amp;quot;changeitchangeitchangeitchangeit&amp;quot; # Uncomment this two lines to user a secret backend manager such as Vault. # More details on https://github.com/ovh/cds/tree/configFile/contrib/secret-backends/secret-backend-vault # backend = &amp;quot;path/to/secret-backend-vault&amp;quot; # backendoptions = &amp;quot;vault_addr=https://vault.mydomain.net:8200 vault_token=09d1f099-3d41-666e-8337-492226789599 vault_namespace=/secret/cds&amp;quot; ################################ # Postgresql Database settings # ################################ [db] user = &amp;quot;cds&amp;quot; password = &amp;quot;cds&amp;quot; name = &amp;quot;cds&amp;quot; host = &amp;quot;localhost&amp;quot; port = 5432 # DB SSL Mode: require, verify-full, or disable sslmode = &amp;quot;disable&amp;quot; maxconn = 20 timeout = 3000 # Uncomment this to retreive database credentials from secret-backend # secret = &amp;quot;cds/db&amp;quot; # The value must be as below # { # &amp;quot;user&amp;quot;: &amp;quot;STRING&amp;quot;, # &amp;quot;password&amp;quot;: &amp;quot;STRING&amp;quot; # } ###################### # CDS Cache Settings # ###################### # If your CDS is made of a unique instance, a local cache if enough, but rememeber that all cached data will be lost on startup. [cache] #Uncomment to use redis as cache #mode = &amp;quot;redis&amp;quot; mode = &amp;quot;local&amp;quot; ttl = 60 # Connect CDS to a redis cache If you more than one CDS instance and to avoid losing data at startup [cache.redis] host = &amp;quot;localhost:6379&amp;quot; # If your want to use a redis-sentinel based cluster, follow this syntax ! &amp;lt;clustername&amp;gt;@sentinel1:26379,sentinel2:26379sentinel3:26379 password = &amp;quot;cds&amp;quot; ############################## # CDS Authentication Settings# ############################## [auth] # The default group is the group in which every new user will be granted at signup defaultgroup = &amp;quot;&amp;quot; # If Authentication is CDS local, you can switch between session based auth or basic auth # localmode = &amp;quot;basic&amp;quot; localmode = &amp;quot;session&amp;quot; [auth.sharedinfra] # Token for shared.infra group. This value will be used when shared.infra will be created # at first CDS launch. This token can be used by CDS CLI, Hatchery, etc... # This is mandatory. 64 char token = &amp;quot;changeitchangeitchangeitchangeitchangeitchangeitchangeitchangeit&amp;quot; [auth.ldap] enable = false host = &amp;quot;&amp;lt;LDAP-server&amp;gt;&amp;quot; port = 636 ssl = true # LDAP Base base = &amp;quot;&amp;quot; # LDAP Bind DN dn = &amp;quot;uid=%s,ou=people,{{.ldapBase}}&amp;quot; # Define CDS user fullname from LDAP attribute fullname = &amp;quot;{{.givenName}} {{.sn}}&amp;quot; ##################### # CDS SMTP Settings # ##################### [smtp] disable = true host = &amp;quot;&amp;quot; port = 23 tls = false user = &amp;quot;&amp;quot; password = &amp;quot;&amp;quot; from = &amp;quot;no-reply@cds.org&amp;quot; ########################## # CDS Artifacts Settings # ########################## # Either filesystem local storage or Openstack Swift Storage are supported [artifact] # mode = &amp;quot;swift# mode = &amp;quot;local&amp;quot; [artifact.local] basedir = &amp;quot;/tmp/cds&amp;quot; [artifact.openstack] url = &amp;quot;&amp;lt;OS_AUTH_URL&amp;gt;&amp;quot; username = &amp;quot;&amp;lt;OS_USERNAME&amp;gt;&amp;quot; password = &amp;quot;&amp;lt;OS_PASSWORD&amp;gt;&amp;quot; tenant = &amp;quot;&amp;lt;OS_TENANT_NAME&amp;gt;&amp;quot; region = &amp;quot;&amp;lt;OS_REGION_NAME&amp;gt;&amp;quot; containerprefix = &amp;quot;&amp;quot; # Use if your want to prefix containers ####################### # CDS Events Settings # ####################### #For now, only Kafka is supported as a event broker [events] [events.kafka] enabled = false broker = &amp;quot;&amp;lt;Kafka SASK/SSL addresses&amp;gt;&amp;quot; topic = &amp;quot;&amp;lt;Kafka topic&amp;gt;&amp;quot; user = &amp;quot;&amp;lt;Kafka username&amp;gt;&amp;quot; password = &amp;quot;&amp;lt;Kafka password&amp;gt;&amp;quot; ########################### # CDS Schedulers Settings # ########################### [schedulers] disabled = false #This is mainly for dev purpose, you should not have to change it #################### # CDS VCS Settings # #################### [vcs] [vcs.polling] disabled = false #This is mainly for dev purpose, you should not have to change it [vcs.repositories] [vcs.repositories.github] statuses_disabled = false # Set to true if you don&#39;t want CDS to push statuses on Github API statuses_url_disabled = false # Set to true if you don&#39;t want CDS to push CDS URL in statuses on Github API clientsecret = &amp;quot;&amp;quot; # You can define here your github client secret if you don&#39;t use secret-backend-manager [vcs.repositories.bitbucket] statuses_disabled = false privatekey = &amp;quot;&amp;quot; # You can define here your bickcket private key if you don&#39;t use secret-backend-manager "
},
{
	"uri": "/getting-started/installation/",
	"title": "Installation",
	"tags": [],
	"description": "",
	"content": "Requirements Download Configuration Database Management Ready to RUN "
},
{
	"uri": "/getting-started/concepts/job/",
	"title": "Job",
	"tags": [],
	"description": "",
	"content": "The Job is more important concept in CDS. It will be composed of steps which will be run sequencially. A Job will be executed is a dedicated workspace and each new run of a job will have a new dedicated workspace. It means that you cannot share a workspace between jobs or between two runs of a job. A Job will be executed by a worker. CDS will choose and provision a worker for dependending of the Requirements you define on your job. If you want to share files or artifact between jobs, stages or pipelines you have to use Artifact upload and Artifact download. You can also share variable between stages, see variables tutorial for more details. "
},
{
	"uri": "/tutorials/worker-model-docker-customized/",
	"title": "Setup Worker Model Docker Customized",
	"tags": [],
	"description": "",
	"content": "A worker model of type docker can be spawned by a Hatchery Docker or Docker Swarm Create a customized Worker Model In this example, we will build a Docker model able to build an AngularJs application with webfonts. To create webfonts, a grunt task (optionnally) requires fontforge and ttfautohint. The following tools must be included in the model: NodeJs and npm bower grunt-cli gulp-cli fontforge ttfautohint We will use the official nodejs image from Docker. In this image, there is already a user named node. For the example, we will compile ttfautohint. Prerequisite To build a Docker model, you need: your favorite text editor a sane installation of Docker https://docs.docker.com/engine/installation/ Dockerfile Copy this content in a file named Dockerfile # User official nodejs docker image FROM node:6.10.1 #Answer &#39;yes&#39; to each question ENV DEBIAN_FRONTEND noninteractive # Upgrade the debian packages RUN (apt-get update &amp;amp;&amp;amp; apt-get upgrade -y -q &amp;amp;&amp;amp; apt-get -y -q autoclean &amp;amp;&amp;amp; apt-get -y -q autoremove) #The official image comes with npm; so we can use it to install some packages RUN npm install -g grunt-cli gulp-cli bower # Install fontforge for our specific need RUN apt-get install -y fontforge # Install packages and compile ttfautohint (still for our specific need) RUN apt-get install -y libharfbuzz-dev libfreetype6-dev libqt4-dev\ &amp;amp;&amp;amp; cd /tmp \ &amp;amp;&amp;amp; curl -L http://download.savannah.gnu.org/releases/freetype/ttfautohint-1.6.tar.gz |tar xz\ &amp;amp;&amp;amp; cd ttfautohint-1.6\ &amp;amp;&amp;amp; ./configure\ &amp;amp;&amp;amp; make\ &amp;amp;&amp;amp; make install # Change user. If you do not specify this command, the user will be root, and in our case, # bower will shout as it cannot be launched by root USER node # Specify a working directory on which the current user has write access # Remember, a curl command will be, first, executed to download the worker WORKDIR /home/node Build it and push it from you shell, type the following command to build the Docker image: docker build --no-cache --pull -t registry.my.infra.net/my/beautiful/worker:latest . If you want to test it, you can lauch your docker in bash mode : docker run -it registry.my.infra.net/my/beautiful/worker:latest /bin/bash pwd fontforge -v exit Now push it docker push registry.my.infra.net/my/beautiful/worker:latest Register your model in CDS In the UI, click on the wheel on the hand right top corner and select *workers&amp;rdquo; (or go the the route #/worker) At the bottom of the page, fill the form Name of your worker My Beautiful type docker image registry.my.infra.net/my/beautiful/worker:latest Click on Add button and that&amp;rsquo;s it Now you can specify this model in prerequisite on your job. Create a new prerequisite of type &amp;ldquo;model&amp;rdquo;, then choose your worker model in list "
},
{
	"uri": "/advanced/worker/token/",
	"title": "Token",
	"tags": [],
	"description": "",
	"content": "Generate a Token Purpose In order to start a worker, you need to provide a worker key to be able to build your pipelines. CLI Run the following command, replace yourgroup with your group $ cds generate token -g yourgroup -e persistent "
},
{
	"uri": "/advanced/write-plugin/",
	"title": "Write a Plugin",
	"tags": [],
	"description": "",
	"content": "A CDS worker executes job, and job is composed of steps. A step is : a builtin action, as GitClone, etc&amp;hellip; read more a user action read more a Plugin Action A Plugin is a Golang Binary. Take a look at https://github.com/ovh/cds/tree/master/sdk/plugin/dummy/dummy_plugin.go Contribute on https://github.com/ovh/cds/tree/master/contrib/plugins "
},
{
	"uri": "/building-pipelines/actions/",
	"title": "Actions",
	"tags": [],
	"description": "",
	"content": "Inside a Job, each steps is based on an action. Types of actions : Built-in actions, available on each CDS Installation User actions, added by CDS Administrators for now Plugins actions, added by CDS Administrators "
},
{
	"uri": "/getting-started/installation/database/",
	"title": "Database Management",
	"tags": [],
	"description": "",
	"content": "CDS provides all needed tools scripts to perform Schema creation and auto-migration. Those tools are embedded inside the api binary. Creation On a brand new database run the following command: $ $PATH_TO_CDS/api database upgrade --db-host &amp;lt;host&amp;gt; --db-host &amp;lt;port&amp;gt; --db-password &amp;lt;password&amp;gt; --db-name &amp;lt;database&amp;gt; --limit 0 Upgrade On an existing database, run the following command on each CDS update: $ $PATH_TO_CDS/api database upgrade --db-host &amp;lt;host&amp;gt; --db-host &amp;lt;port&amp;gt; --db-password &amp;lt;password&amp;gt; --db-name &amp;lt;database&amp;gt; More details Read more about CDS Database Management "
},
{
	"uri": "/tutorials/worker-model-openstack/",
	"title": "Setup Worker Model Openstack",
	"tags": [],
	"description": "",
	"content": "CDS build using OVH.com Openstack infrastructure Create Openstack user In OVH manager, in cloud section, click on the menu on the Servers&amp;gt;Openstack item. You will be able to create an Openstack user, enter description (name and password will be generated). Add Openstack worker model We need to define an Openstack worker model to have Openstack hatchery booting workers. We will create a model called docker: With low hardware capacity (vps-ssd-1) On Debian 8 With docker ready to use Git installed First, define a udata file. It is a shell script executed just after the boot sequence complete. Our docker udata will look like this: # Install docker cd $HOME sudo apt-get -y --force-yes update &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 apt-get install -y --force-yes apt-transport-https ca-certificates &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 apt-key adv --keyserver hkp://p80.pool.sks-keyservers.net:80 --recv-keys 58118E89F3A912897C070ADBF76221572C52609D sudo mkdir -p /etc/apt/sources.list.d sudo sh -c &amp;quot;echo deb https://apt.dockerproject.org/repo debian-jessie main &amp;gt; /etc/apt/sources.list.d/docker.list&amp;quot; sudo apt-get -y --force-yes update &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo apt-cache policy docker-engine &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo apt-get install -y --force-yes docker-engine &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo service docker start &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 # Non-root access sudo groupadd docker &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo gpasswd -a ${USER} docker &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo service docker restart &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 # Basic build binaries sudo apt-get -y --force-yes install curl git &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 sudo apt-get -y --force-yes install binutils &amp;gt;&amp;gt; /tmp/user_data 2&amp;gt;&amp;amp;1 Last step, define worker model in cds: $ cds worker model add docker openstack --image=&amp;quot;Debian 8&amp;quot; --flavor=&amp;quot;vps-ssd-1&amp;quot; --userdata=&amp;quot;./docker.udata&amp;quot; Declare docker and git capabilities $ cds worker model capability add docker docker binary docker $ cds worker model capability add docker git binary git "
},
{
	"uri": "/getting-started/concepts/step/",
	"title": "Step",
	"tags": [],
	"description": "",
	"content": "The steps of a job is the list of the different operation performed by the CDS worker. Each steps is based on an Action which is defined by CDS. The list of all actions is defined on *&amp;lt;your cds url ui&amp;gt;/#/action*. On the very first step failed, the job is marked as Failed and execution is stopped. You can define a Step as final. It mean that even if the job is failed, the step will be executed. The final steps are executed after all other steps. "
},
{
	"uri": "/getting-started/installation/ready-to-run/",
	"title": "Ready to RUN",
	"tags": [],
	"description": "",
	"content": "Docker Compose "
},
{
	"uri": "/tutorials/service-link-requirement-nginx/",
	"title": "Service Requirement Nginx",
	"tags": [],
	"description": "",
	"content": "Add the service requirement Name: mypg. This will be the service hostname Type: service Value: nginx:1.11.1. This is the name of docker image to link to current job And a requirement model which allow you to execute apt-get install -y postgresql-client worker-model-docker-simple.md Add a step of type script docker image nginx:1.11.1 start a nginx at startup. So, it&amp;rsquo;s now available on http://mynginx curl -v -X GET http://mynginx Execute Pipeline See output: "
},
{
	"uri": "/building-pipelines/templates/",
	"title": "Templates",
	"tags": [],
	"description": "",
	"content": "Templates from CDS Contributions : cds-template-cds-plugin cds-template-cds-template cds-template-deploy-marathon-app cds-template-only-git-clone-job cds-template-plain "
},
{
	"uri": "/building-pipelines/variables/",
	"title": "Variables",
	"tags": [],
	"description": "",
	"content": "In CDS, it is possible to define variables at different levels: Project Environment Application Variable types Existing variable types: String Text Boolean Number Password Key Placeholder format All variables in CDS can be invoked using the simple {{.VAR}} format. To simplify the use between all the variable sources, we have defined the following prefixes: Action variable: {{.VAR}} Builtin CDS: {{.cds.VAR}} Git: {{.git.VAR}} Pipeline: {{.cds.pip.VAR}} Application: {{.cds.app.VAR}} Environment: {{.cds.env.VAR}} Project: {{.cds.proj.VAR}} Exported variable at build time: {{.cds.build.VAR}} Builtin variables Here is the list of builtin variables, generated for every build: {{.cds.project}} The name of the current project {{.cds.environment}} The name of the current environment {{.cds.application}} The name of the current application {{.cds.pipeline}} The name of the current pipeline {{.cds.stage}} The name of the current stage {{.cds.job}} The name of the current job {{.cds.workspace}} Current job&amp;rsquo;s workspace. It&amp;rsquo;s a directory. In a step script, {{.cds.workspace}} == $HOME {{.cds.version}} The number of the current version {{.cds.parent.application}} The name of the application that triggered the current build {{.cds.parent.pipeline}} The name of the pipeline that triggered the current build {{.cds.triggered_by.email}} Email of the user that run the current build {{.cds.triggered_by.fullname}} Full name of the user that run the current build {{.cds.triggered_by.username}} User that run the current build The .version variable {{.cds.version}} CDS version is a builtin variable equals to the buildNumber of the last pipeline of type “build”. This variable is transmitted through triggers with the same value to testing and deployment pipelines. Export a variable inside a step In a step of type script, you can export variable as: $ worker export varname thevalue You can now use {{.cds.build.varname}} in further steps and stages. Shell Environment Variable All CDS variables, except password type can use used as plain environment variable. Theses lines will have the same output echo &#39;{{.cds.parent.application}}&#39; echo $CDS_PARENT_APPLICATION Git variables Here is the list of git variables: {{.git.hash}} {{.git.url}} {{.git.http_url}} {{.git.branch}} {{.git.author}} {{.git.message}} "
},
{
	"uri": "/advanced/worker/",
	"title": "Worker",
	"tags": [],
	"description": "",
	"content": "A pipeline is structured in sequential stages containing one or multiple concurrent jobs. A Job will be executed by a worker. Building your own worker model enable you to integrate your own tools, or to customize the tools you need to use. For instance, to build an AngularJs application, you shall need a worker capable of installing npm tools, importing bower packages (these are nodeJs tools), building webfonts with fontforge, &amp;hellip; What is a worker Basically, a worker is a binary. This binary can be launched inside a Docker Containers, or on a Host (as VM Openstack). Worker cycle of life If the worker is spawned by a Hatchery, the Docker Container or Host where the worker will be lauched must contains a sane installation of &amp;ldquo;curl&amp;rdquo;. So, in the case of a worker model of type &amp;ldquo;docker&amp;rdquo;, the docker image must contains curl in PATH. Why would you need to setup your own worker ? There is several cases where one would need to setup his own worker: Perform incremental build Build on a specific architecture Perform integration tests in a specific network How does this work ? Workers authenticate on CDS with a token and have the same permissions as the user who generated it. Bottom line, if you can access the application, your worker will too. "
},
{
	"uri": "/advanced/",
	"title": "Advanced",
	"tags": [],
	"description": "",
	"content": "Hatcheries Repositories Manager Write a Plugin Worker "
},
{
	"uri": "/building-pipelines/requirements/",
	"title": "Requirements",
	"tags": [],
	"description": "",
	"content": "A Job will be executed by a worker. CDS will choose and provision a worker for dependending of the requirements you define on your job. You can set as many requirements as you want, following those rules : Only one model can be set as requirement Only one hostname can be set as requirement Memory and Services requirements are availabe only on Docker models Note on Service Requirement A Service in CDS is a docker container which is linked with your base image. To summarize, if you add mysql as service requirement to your pipeline job, the required image will then be used to create a container that is linked to the build container. How to When editing a pipeline job, choose your model as usual. Then add a new service requirement, the name you set will be the service&amp;rsquo;s hostname, set the docker image for the service as the value. When the pipeline will be triggered, a worker defined by the model will be spawned with a link (https://docs.docker.com/engine/userguide/networking/default_network/dockerlinks/) to the service you defined as requirement. Environment variables You can defined environment variables of the service by setting requirement value as : registry.ovh.net/official/postgres:9.5.3 POSTGRES_USER=myuser POSTGRES_PASSWORD=mypassword Tutorials Tutorial - Service Link Requirement Nginx Tutorial - Service Link Requirement PostgreSQL "
},
{
	"uri": "/tutorials/service-link-requirement-pg/",
	"title": "Service Requirement PostgreSQL",
	"tags": [],
	"description": "",
	"content": "Add the service requirement Requirement Service Name: mypg. This will be the service hostname Type: service Value: postgres:9.5.3 POSTGRES_USER=myuser POSTGRES_PASSWORD=mypassword. This is the name of docker image to link to current job And a requirement model which allow you to execute apt-get install -y postgresql-client, see HowTo Add a step of type script docker image postgres:9.5.3 start a nginx at startup. So, it&amp;rsquo;s now available on http://mynginx #!/bin/bash set -ex apt-get update apt-get install -y postgresql-client PGPASSWORD=mypassword psql -U myuser -h mypg &amp;lt;&amp;lt;EOF \x SELECT version(); EOF Execute Pipeline See output: "
},
{
	"uri": "/tutorials/git-track/",
	"title": "Git track ",
	"tags": [],
	"description": "",
	"content": "Introduction This tutorial introduce the cds track &amp;lt;git commit&amp;gt; function of CDS cli. Goal: Immediate feedback cds track aims to display in your terminal the status of the pipeline building code refered by given commit hash. Push your branch, start cds track and get immediate feedback. Git track will display all pipelines related to given hash. This means triggered testing and deployment pipelines will be displayed. Git alias sugar To enhance even more your daily routine, you can create a git alias: $ cat ~/.gitconfig [alias] track = !cds track $(git rev-parse HEAD) "
},
{
	"uri": "/tutorials/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": "Worker Setup Setup Worker Model Docker Simple Setup Worker Model Docker Customized Setup Worker Model Openstack Service Requirement Nginx Service Requirement PostgreSQL Git track "
},
{
	"uri": "/",
	"title": "",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/advanced/",
	"title": "Advanceds",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/building-pipelines/actions/builtin/artifact-download/",
	"title": "Artifact Download",
	"tags": [],
	"description": "",
	"content": "Artifact Download Action is a builtin action, you can&amp;rsquo;t modify it. This action can be used to get artifact uploaded by the Artifact Upload action Action Parameter application: Application from where artifacts will be downloaded pipeline: Pipeline from where artifacts will be downloaded tag: Tag set in the Artifact Upload action path: Path where artifacts will be downloaded Example of Job Configuration Download artifact from the parent pipeline Download artifact from the previous stage "
},
{
	"uri": "/building-pipelines/actions/builtin/artifact-upload/",
	"title": "Artifact Upload",
	"tags": [],
	"description": "",
	"content": "Artifact Upload Action Artifact Upload Action is a builtin action, you can&amp;rsquo;t modify it. This action can be used to upload artifact in CDS. This is the good way to share files between pipelines or stages. Action Parameter path: Path of file to upload tag: Tag to apply to your file. Example of Job Configuration With a tag to indicate the build version With a latest tag "
},
{
	"uri": "/building-pipelines/",
	"title": "Building-pipelines",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/categories/",
	"title": "Categories",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/getting-started/installation/ready-to-run/docker-compose/",
	"title": "Docker Compose",
	"tags": [],
	"description": "",
	"content": "Run with Docker-Compose The docker-compose.yml contains: cds-db service with a postgresql cds-cache service with a redis cds-migrate service to prepare DB tables. cds-api service cds-ui service cds-hatchery-swarm service cds-hatchery-local service Docker compose is very convenient to launch CDS for testing it. But this is not recommended for a Production Installation. How to run $ git clone https://github.com/ovh/cds.git $ cd cds $ export HOSTNAME=$(hostname) # Create PG Database $ docker-compose up --no-recreate -d cds-db # check if db is UP # check if last log is &amp;quot;LOG: database system is ready to accept connections&amp;quot; $ docker-compose logs $ docker-compose up --no-recreate cds-migrate # You should have this log: &amp;quot;cds_cds-migrate_1 exited with code 0&amp;quot; # run API and UI $ docker-compose up cds-api cds-ui Open a browser on http://localhost:2015, then register a new user. As there is no SMTP server configured in docker-compose.yml file, run docker-compose logs to get URL for validate the registration. Prepare Project, Pipeline and Application On UI http://localhost:2015: Create a project Create an application, with an void pipeline Create a pipeline, attached to application On Pipeline, add a stage and a job Inside job, add a step of type &amp;ldquo;script&amp;rdquo; In script content, add theses lines: #!/bin/bash set -ex echo &amp;quot;foo&amp;quot; sleep 10 echo &amp;quot;bar&amp;quot; Run Pipeline Run pipeline. As you can see now, you pipeline is in &amp;ldquo;waiting status&amp;rdquo;. You have to run a CDS Worker or a CDS Hatchery which aims to create workers. Let&amp;rsquo;s run an hatchery with docker-compose. We will spawn a containers with a hatchery in local mode. Workers will be spawn inside this container. $ docker-compose up cds-hatchery-local Running a hatchery &amp;ldquo;local&amp;rdquo; in a container is not recommanded. Use this way only for test purpose. After running this Hatchery, a worker will be spawned. Your pipeline will be in &amp;ldquo;Building&amp;rdquo;, then &amp;ldquo;Success&amp;rdquo; status. Hatchery Docker Swarm The docker-compose.yml runs hatchery belonging to the shared.infra groups. A local hatchery spawn worker on same host than hatchery. This is usually useful for specific cases, as running job on specific hardware. But this hatchery does not make it possible to respect the isolation of workpaces of workers as they share the same workspace. There is another hatchery configured in docker-compose.yml file: a &amp;lsquo;swarm hatchery&amp;rsquo; Please check that your docker installation allows docker API calls on tcp://${HOSTNAME}:2375 Otherwise, please update environment variable DOCKER_HOST: tcp://${HOSTNAME}:2375 in docker-compose.yml $ docker-compose up cds-hatchery-swarm A swarm hatchery spwan CDS Worker inside dedicated container. This ensures isolation of the workspaces and resources. Next with Actions, Plugins and Templates You can download CDS CLI from https://github.com/ovh/cds/releases Run: $ mv cds-linux-amd64 cds $ chmod +x cds $ ./cds login # enter: http://${HOSTNAME}:8081 as CDS Endpoint Import actions, example: $ cds action add --url https://raw.githubusercontent.com/ovh/cds/master/contrib/actions/cds-docker-package.hcl Import plugins, example: # download plugin-download-linux-amd64 from https://github.com/ovh/cds/releases $ cds admin plugin add ./plugin-download-linux-amd64 Import templates, example: # download cds-template-plain-linux-amd64 from https://github.com/ovh/cds/releases $ cds admin templates add ./cds-template-plain-linux-amd64 Go further First pipeline with CDS CLI read more How to use Openstack infrastructure to spawn CDS container read more Link CDS to a repository manager, as Github or Bitbucket read more Learn more about CDS variables read more "
},
{
	"uri": "/getting-started/",
	"title": "Getting-starteds",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/building-pipelines/actions/builtin/gitclone/",
	"title": "GitClone",
	"tags": [],
	"description": "",
	"content": "GitClone is a builtin action, you can&amp;rsquo;t modify it. This action clone a repository into a new directory. Git Clone will be done with a depth of 1. You can use a privateKey, this is usually a project or application variable of type key. {{.cds.app.a-key.pub}} Parameters url - mandatory - URL must contain information about the transport protocol, the address of the remote server, and the path to the repository. privateKey - optional - the private key to be able to git clone from ssh user - optional - the user to be able to git clone from https with authentication password - optional - the password to be able to git clone from https with authentication branch - optional - Instead of pointing the newly created HEAD to the branch pointed to by the cloned repository’s HEAD, point to {{.git.branch}} branch instead. commit - optional - the current branch head (HEAD) to the commit directory - optional - the name of a directory to clone into. "
},
{
	"uri": "/building-pipelines/actions/builtin/junit/",
	"title": "JUnit",
	"tags": [],
	"description": "",
	"content": "JUnit is a builtin action, you can&amp;rsquo;t modify it. This action parse given file to extract Unit Test results. Parameters path: Path to junit xml file "
},
{
	"uri": "/building-pipelines/actions/builtin/script/",
	"title": "Script",
	"tags": [],
	"description": "",
	"content": "Script is a builtin action, you can&amp;rsquo;t modify it. This action execute a script, written in script attribute Parameters script: Content of your script. You can put #!/bin/bash or #!/bin/perl at first line. Make sure that the binary used is in the pre-requisites of action "
},
{
	"uri": "/getting-started/concepts/stage/",
	"title": "Stage",
	"tags": [],
	"description": "",
	"content": "Usually in CDS a build pipeline is structured of the following stages : Compile stage : Build the binaries Analysis &amp;amp; Unit Tests stage : Run all unit tests and analyse code quality Packaging stage : Build the final package, Virtual Machine Image or Docker Image. In CDS, stages are executed sequentially if the previous stage is successfull. You can define trigger conditions on a stage, to enable it on certain conditions. For instance, you want to run the Compile Stage and Analysis &amp;amp; Unit Tests stage on all branches but the Packaging Stage on branches master and develop only. A Stage is a set of jobs which will be run in parallel. "
},
{
	"uri": "/tags/",
	"title": "Tags",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/tutorials/",
	"title": "Tutorials",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/building-pipelines/actions/user/cds-docker-package/",
	"title": "cds-docker-package",
	"tags": [],
	"description": "",
	"content": "Build image and push it to docker repository Parameters dockerfileDirectory: Directory which contains your Dockerfile. dockerOpts: Docker options, Enter &amp;ndash;no-cache &amp;ndash;pull if you want for example dockerRegistry: Docker Registry. Enter myregistry for build image myregistry/myimage:mytag imageName: Name of your docker image, without tag. Enter myimage for build image myregistry/myimage:mytag imageTag: Tag of your docker image. Enter mytag for build image myregistry/myimage:mytag. {{.cds.version}} is a good tag from CDS. You can use many tags: firstTag,SecondTag Example : {{.cds.version}},latest Requirements docker: type:binary Value:docker bash: type:binary Value:bash More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/user/cds-nexus-upload/",
	"title": "cds-nexus-upload",
	"tags": [],
	"description": "",
	"content": "Upload file on Nexus Parameters version: Version of the artifact. Supports resolving of &amp;lsquo;LATEST&amp;rsquo;, &amp;lsquo;RELEASE&amp;rsquo; and snapshot versions (&amp;lsquo;1.0-SNAPSHOT&amp;rsquo;) too. files: Regex of files you want to upload packaging: Packaging type of the artifact login: Login for nexus password: Password for nexus extension: Extension of the artifact artifactId: Artifact id of the artifact url: Nexus URL repository: Nexus repository that the artifact is contained in groupId: Group id of the artifact Requirements bash: type:binary Value:bash curl: type:binary Value:curl More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/user/cds-perl-test/",
	"title": "cds-perl-test",
	"tags": [],
	"description": "",
	"content": "Test with prove on perl source code Parameters testDirectory: Directory where is Perl Source Code Requirements perl: type:binary Value:perl bash: type:binary Value:bash prove: type:binary Value:prove More documentation on Github "
},
{
	"uri": "/building-pipelines/templates/cds-template-cds-plugin/",
	"title": "cds-template-cds-plugin",
	"tags": [],
	"description": "",
	"content": "This template creates a pipeline for building CDS Plugin with: A &amp;ldquo;Commit Stage&amp;rdquo; with one job &amp;ldquo;Compile&amp;rdquo; Job contains two steps: GitClone and CDS_GoBuild Parameters repo: Your source code repository package.root: example: github.com/ovh/cds package.sub: Directory inside your repository where is the plugin. Enter &amp;ldquo;contrib/plugins/your-plugin&amp;rdquo; for github.com/ovh/cds/contrib/plugins/your-plugin More More documentation on Github "
},
{
	"uri": "/building-pipelines/templates/cds-template-cds-template/",
	"title": "cds-template-cds-template",
	"tags": [],
	"description": "",
	"content": "This template creates a pipeline for building CDS Template with: A &amp;ldquo;Commit Stage&amp;rdquo; with one job &amp;ldquo;Compile&amp;rdquo; Job contains two steps: GitClone and CDS_GoBuild Parameters repo: Your source code repository package.root: example: github.com/ovh/cds package.sub: Directory inside your repository where is the template. Enter &amp;ldquo;contrib/templates/your-plugin&amp;rdquo; for github.com/ovh/cds/contrib/templates/your-plugin More More documentation on Github "
},
{
	"uri": "/building-pipelines/templates/cds-template-deploy-marathon-app/",
	"title": "cds-template-deploy-marathon-app",
	"tags": [],
	"description": "",
	"content": "This template creates: a deployment pipeline with one stage, containing and one job job calls plugin-marathon an application with a variable named &amp;ldquo;marathon.config&amp;rdquo; uses environment variables marathonHost, password and user Please update Application / Environment Variables after creating application. Parameters docker.image: Your docker image without the tag marathon.appID: Your marathon application ID marathon.config: Content of your marathon.json file More More documentation on Github "
},
{
	"uri": "/building-pipelines/templates/cds-template-only-git-clone-job/",
	"title": "cds-template-only-git-clone-job",
	"tags": [],
	"description": "",
	"content": "This template creates: a build pipeline with one stage, containing one job job contains 2 steps: GitClone and a empty script. Pipeline name contains Application name. If you want to make a reusable pipeline, please consider updating this name after creating application. Parameters repo: Your source code repository More More documentation on Github "
},
{
	"uri": "/building-pipelines/templates/cds-template-plain/",
	"title": "cds-template-plain",
	"tags": [],
	"description": "",
	"content": "This template creates: a build pipeline with two stages: Commit Stage and Packaging Stage a deploy pipeline with one stage: Deploy Stage Commit Stage : run git clone run make build Packaging Stage: run docker build and docker push Deploy Stage: it&amp;rsquo;s en empty script Packaging and Deploy are optional. Parameters repo: Your source code repository withPackage: Do you want a Docker Package? withDeploy: Do you want an deploy Pipeline? More More documentation on Github "
},
{
	"uri": "/_header/",
	"title": "header",
	"tags": [],
	"description": "",
	"content": ""
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-download/",
	"title": "plugin-download",
	"tags": [],
	"description": "",
	"content": "This is a plugin to download file from URL Parameters headers: specific headers to add to your request (&amp;ldquo;headerName&amp;rdquo;=&amp;ldquo;value&amp;rdquo; newline separated list) url: the url of your file filepath: the destination of your file to be copied More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-group-tmpl/",
	"title": "plugin-group-tmpl",
	"tags": [],
	"description": "",
	"content": "This actions helps you generate a marathon group application file. It takes a config template file as a single application, and creates the group with the variables specified for each application in the applications files. Check documentation on text/template for more information https://golang.org/pkg/text/template. Parameters config: Template file to use output: Output path for generated file (default to .out or just trimming .tpl extension) applications: Applications file variables More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-kafka-publish/",
	"title": "plugin-kafka-publish",
	"tags": [],
	"description": "",
	"content": "This action helps you to send data through Kafka across every network. You are able to send a custom &amp;quot;message&amp;quot; file and all the artifacts you want: there is no file size limit. To improve security, you can encrypt the files content with a GPG Key. From the consummer side, you will need to decrypt files content with you GPG private key and your passphrase. This action is a CDS Plugin packaged as a single binary file you can download and use to listen and consume data coming from CDS through Kafka. CDS can also wait for an acknowledgement coming from the consummer side. To send the acknowledgement, you can again use the plugin binary. For more details, see readme file of the plugin. Parameters kafkaAddresses: Kafka Addresses topic: Kafka Topic message: Kafka Message kafkaPassword: Kafka Password kafkaGroup: Kafka Consumer Group (used for acknowledgment) artifacts: Artifacts list (comma separated) publicKey: GPG Public Key (ASCII armored format) waitForAck: Wait for Ack waitForAckTopic: Kafka Topic. Used only if &amp;ldquo;waitForAck&amp;rdquo; is true. waitForAckTimeout: Ack timeout (seconds). Used only if &amp;ldquo;waitForAck&amp;rdquo; is true. kafkaUser: Kafka User More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-marathon/",
	"title": "plugin-marathon",
	"tags": [],
	"description": "",
	"content": "This action helps you to deploy on Mesos/Marathon. Provide a marathon.json file to configure deployment. Your marathon.json file can be templated with cds variables &amp;ldquo;{{.cds.variables}}&amp;rdquo;. Enable &amp;ldquo;waitForDeployment&amp;rdquo; option to ensure deployment is successfull. Parameters url: Marathon URL http://127.0.0.1:8081,http://127.0.0.1:8082,http://127.0.0.1:8083 user: Marathon User (please use project, application or environment variables) password: Marathon Password (please use project, application or environment variables) configuration: Marathon application configuration file (json format) waitForDeployment: Wait for instances deployment. If set, CDS will wait for all instances to be deployed until timeout is over. All instances deployment must be done to get a successful result. If not set, CDS will consider a successful result if marathon accepts the provided configuration. insecureSkipVerify: Skip SSL Verify if you want to use self-signed certificate timeout: Marathon deployment timeout (seconds). Used only if &amp;ldquo;waitForDeployment&amp;rdquo; is true. More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-ssh-cmd/",
	"title": "plugin-ssh-cmd",
	"tags": [],
	"description": "",
	"content": "This plugin helps you to run cmd on remote server over ssh. Parameters username: Username privateKey: SSH RSA private key hostnames: Hostnames (comma separated values) command: Command timeout: Timeout (seconds) commandTimeout: Command Timeout (seconds) More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-tmpl/",
	"title": "plugin-tmpl",
	"tags": [],
	"description": "",
	"content": "This action helps you generates a file using a template file and text/template golang package. Check documentation on text/template for more information https://golang.org/pkg/text/template. Parameters file: Template file to use output: Output path for generated file (default to .out or just trimming .tpl extension) params: Parameters to pass on the template file (key=value newline separated list) More More documentation on Github "
},
{
	"uri": "/building-pipelines/actions/plugins/plugin-venom/",
	"title": "plugin-venom",
	"tags": [],
	"description": "",
	"content": "This plugin helps you to run venom. Venom: https://github.com/runabove/venom. Add an extra step of type junit on your job to view tests results on CDS UI. Parameters path: Path containers yml venom files. Format: adirectory/, ./aTest.yml, ./foo/b/*/z.yml exclude: Exclude some files, one file per line parallel: Launch Test Suites in parallel. Enter here number of routines output: Directory where output xunit result file details: Output Details Level: low, medium, high loglevel: Log Level: debug, info, warn or error More More documentation on Github "
}]